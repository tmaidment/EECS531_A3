{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EECS531 - A3\n",
    "## Tristan Maidment (tdm47)\n",
    "\n",
    "#### Goal\n",
    "This is the first assignment that requires a neural network to be implemented. Keras provides a very hands off approach for defining a neural network.  Although this is useful for helping build the intuition of how to structure a neural network, I would like a full understanding of how it works, e.g. defining one by hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mnist\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to download the mnist dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = mnist.train_images()\n",
    "train_labels = mnist.train_labels()\n",
    "\n",
    "test_images = mnist.test_images()\n",
    "test_labels = mnist.test_labels()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing to define is the classifier functions used at each layer.  For the purpose of speed, the main classifier used will be the ReLu function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return np.maximum(x, 0)\n",
    "\n",
    "def d_relu(x):\n",
    "    return np.maximum(x, 0 ) * x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "since we are using a numpy implentation and everything will be super slow, pooling will save my life"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#only supports pool sizes that fit in the img\n",
    "def max_pool(img, value):\n",
    "    h, w = img.shape\n",
    "    h_pool, w_pool = int(h/value), int(w/value)\n",
    "    pool = np.empty((h_pool, w_pool))\n",
    "    for i in range(h_pool):\n",
    "        for j in range(w_pool):\n",
    "            pool[i, j] = img[i*value:(i+1)*value,j*value:(j+1)*value].max()\n",
    "    return pool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define functions used to define the weights of each layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x kernels of y size\n",
    "def conv_weights(x, y):\n",
    "    c = []\n",
    "    for i in range(x):\n",
    "        c.append(np.random.randn(y, y)) #init with random weights\n",
    "    return np.array(c)\n",
    "\n",
    "# flatten layer weights\n",
    "# x - input dimensions\n",
    "# y - output dimensions\n",
    "def flat_weights(x, y):\n",
    "    return np.random.randn(x, y)\n",
    "\n",
    "def bias_weights(x):\n",
    "    return np.random.randn(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "layer feed forwards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_feed_forward(img, kernels):\n",
    "    c = [] #\n",
    "    c_l = [] #linear\n",
    "    for i in range(len(kernels)):\n",
    "        # conv layer\n",
    "        img_conv = cv2.filter2D(img, -1, kernels[i])\n",
    "        c_l.append(img_conv)\n",
    "        img_relu = relu(img_conv)\n",
    "        #img_pool = max_pool(img_relu, 2)\n",
    "        c.append(img_relu)\n",
    "    return np.array(c), np.array(c_l)\n",
    "\n",
    "def flatten_feed_forward(convs, weights):\n",
    "    f = []\n",
    "    for i in range(len(convs)):\n",
    "        f.append(np.ravel(convs[i]))\n",
    "    reshape = np.expand_dims(np.hstack(f), axis=0)\n",
    "    flat = np.dot(reshape, weights)\n",
    "    return relu(flat), reshape\n",
    "\n",
    "def dense_feed_forward(layer, weights, bias):\n",
    "    z = np.add(np.dot(layer, weights), bias)\n",
    "    #z = np.dot(layer, weights)\n",
    "    return relu(z), z\n",
    "\n",
    "# serious switch this to cross entropy\n",
    "def cost_feed_forward(layer, label):\n",
    "    return np.multiply(np.square(np.sum(layer - label)), 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "layer back projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_back_propagation(layer, label):\n",
    "    return np.multiply(2, np.subtract(layer, label)) #gradient of the \n",
    "\n",
    "def dense_back_propagation(inner, prev_layer):\n",
    "    #print(inner.shape, prev_layer.shape)\n",
    "    return np.outer(d_relu(inner), prev_layer) #might have to be dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_likelihood(vector):\n",
    "    return np.argmax(vector)\n",
    "\n",
    "def one_hot_label(label):\n",
    "    ret = np.zeros(10)\n",
    "    ret[label] = 1\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "shallow neural network definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 3\n",
    "#w_l0 = conv_weights(6, 3) # 6 3x3 kernels \n",
    "w_0 = flat_weights(784, 256) # flatten to a 256 hidden layer\n",
    "w_1 = flat_weights(256, 10) # flatten to a 10 node output layer\n",
    "b_0 = bias_weights(256)\n",
    "b_1 = bias_weights(10)\n",
    "cost = 0\n",
    "alpha = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated value: 5 Actual Value: 5\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (256,) (10,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-c49f154abf86>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mb_1\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta_cost\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0mb_0\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta_cost\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mw_1a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelta_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta_cost\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (256,) (10,) "
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "        for i in range(len(train_images)):\n",
    "            img = train_images[i]\n",
    "            label = train_labels[i]\n",
    "            \n",
    "            img_input = img.ravel()\n",
    "            \n",
    "            a_0, z_0 = dense_feed_forward(img_input, w_0, b_0)\n",
    "            a_1, z_1 = dense_feed_forward(a_0, w_1, b_1)\n",
    "            \n",
    "            cost += cost_feed_forward(a_1, one_hot_label(label))\n",
    "            print(\"Estimated value:\",cost_likelihood(a_1), \"Actual Value:\", label)\n",
    "            \n",
    "            delta_cost = cost_back_propagation(a_1, one_hot_label(label))\n",
    "            #print(delta_cost.shape)\n",
    "            delta_1 = dense_back_propagation(z_1, a_0)\n",
    "            #print(delta_1.shape, w_1.shape)\n",
    "            \n",
    "            delta_0 = dense_back_propagation(z_0, w_0)\n",
    "            #print(delta_0.shape, w_0.shape)\n",
    "            \n",
    "            b_1 += np.multiply(z_1, delta_cost)\n",
    "            b_0 += np.multiply(z_0, delta_cost)\n",
    "            \n",
    "            w_1a = np.multiply(delta_1.T, delta_cost)\n",
    "            print(\"w_1a\", np.mean(w_1a))\n",
    "            w_1 += w_1a#np.multiply(alpha, w_1a)\n",
    "            \n",
    "            w_0a = np.multiply(delta_0.T, delta_cost)\n",
    "            print(\"w_0a\", np.mean(w_0a))\n",
    "            w_0 += w_0a#np.multiply(alpha, w_0a)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
