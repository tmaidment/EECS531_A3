{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EECS531 - A3\n",
    "## Tristan Maidment (tdm47)\n",
    "\n",
    "#### Goal\n",
    "The goal of this assignment is to compare the performance of network depth to verification set performance.  For this experiment, we will be comparing the a \"shallow\" or standard CNN, with one just convolutional and output layer to a deep CNN.\n",
    "\n",
    "In A2, we learned about PCA as a powerful method for resembling images.  The last exercise included an implementation of the technique, and I will attempt to compare it's performance in comparison to CNNs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation\n",
    "For this project, we will be using the popular MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "epochs = 15\n",
    "simple_score, deep_score, pca_score = np.zeros(epochs), np.zeros(epochs), np.zeros(epochs)\n",
    "\n",
    "(imgTrain, labelTrain), (imgTest, labelTest) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set in shape of  (60000, 28, 28, 1)  with element type  <class 'float'>\n",
      "Testing set in shape of   (10000, 28, 28, 1)  with element type  <class 'float'>\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "imgRows, imgCols = 28, 28\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    imgTrain = imgTrain.reshape(imgTrain.shape[0], 1, imgRows, imgCols)\n",
    "    imgTest  = imgTest.reshape(imgTest.shape[0], 1, imgRows, imgCols)\n",
    "    smpSize  = (1, imgRows, imgCols)\n",
    "else:\n",
    "    imgTrain = imgTrain.reshape(imgTrain.shape[0], imgRows, imgCols, 1)\n",
    "    imgTest  = imgTest.reshape(imgTest.shape[0], imgRows, imgCols, 1)\n",
    "    smpSize  = (imgRows, imgCols, 1)\n",
    "\n",
    "imgTrain = imgTrain.astype('float') / 255\n",
    "imgTest  = imgTest.astype('float') / 255\n",
    "\n",
    "print('Training set in shape of ', imgTrain.shape, ' with element type ', type(imgTrain.item(0)))\n",
    "print('Testing set in shape of  ', imgTest.shape, ' with element type ', type(imgTrain.item(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncat = 10 \n",
    "onehotTrain = keras.utils.to_categorical(labelTrain, ncat)\n",
    "onehotTest  = keras.utils.to_categorical(labelTest, ncat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple CNN\n",
    "The first model that we will be testing is a simple CNN that uses a single convolutional layer, pooling layer, and dense layer.  For the models being tested, we will plot the validation set percentage for each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(4, 4),\n",
    "                 activation='relu',\n",
    "                 input_shape=smpSize))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(ncat, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 21s 346us/step - loss: 0.3081 - acc: 0.9120 - val_loss: 0.1319 - val_acc: 0.9628\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 20s 339us/step - loss: 0.1074 - acc: 0.9703 - val_loss: 0.0783 - val_acc: 0.9771\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 22s 363us/step - loss: 0.0770 - acc: 0.9786 - val_loss: 0.0625 - val_acc: 0.9808\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 19s 325us/step - loss: 0.0637 - acc: 0.9812 - val_loss: 0.0547 - val_acc: 0.9825\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 22s 368us/step - loss: 0.0557 - acc: 0.9839 - val_loss: 0.0513 - val_acc: 0.9842\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 23s 378us/step - loss: 0.0497 - acc: 0.9855 - val_loss: 0.0506 - val_acc: 0.9839\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 20s 339us/step - loss: 0.0460 - acc: 0.9867 - val_loss: 0.0450 - val_acc: 0.9848\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 23s 376us/step - loss: 0.0421 - acc: 0.9880 - val_loss: 0.0433 - val_acc: 0.9851\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 21s 345us/step - loss: 0.0392 - acc: 0.9886 - val_loss: 0.0428 - val_acc: 0.9861\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 19s 322us/step - loss: 0.0364 - acc: 0.9901 - val_loss: 0.0480 - val_acc: 0.9843\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 19s 320us/step - loss: 0.0339 - acc: 0.9904 - val_loss: 0.0415 - val_acc: 0.9867\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 21s 345us/step - loss: 0.0321 - acc: 0.9910 - val_loss: 0.0446 - val_acc: 0.9858\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 21s 345us/step - loss: 0.0304 - acc: 0.9914 - val_loss: 0.0417 - val_acc: 0.9866\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 21s 353us/step - loss: 0.0285 - acc: 0.9920 - val_loss: 0.0401 - val_acc: 0.9868\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 21s 342us/step - loss: 0.0269 - acc: 0.9925 - val_loss: 0.0404 - val_acc: 0.9874\n"
     ]
    }
   ],
   "source": [
    "for i in range(epochs):\n",
    "    model.fit(imgTrain, onehotTrain, validation_data=(imgTest, onehotTest), batch_size=128, epochs=1, verbose=1)\n",
    "    score = model.evaluate(imgTest, onehotTest, verbose=0)\n",
    "    simple_score[i] = score[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deep CNN\n",
    "This CNN is resembles a more traditional approach to a deep learning CNN.  It consists of two convolutional layers, a max pooling layer, two more convolutional layers, a second max pooling layer, then two dense layers.  The convolutional layers consist of kernels of both increaseing amount and size.  The purpose of this identify smaller features first, with the small kernels.  These small features are then classified using the larger kernels, which should capture some of the bigger features of the image.  I believe that this should reduce the variance that results from the various ways which people write digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "\n",
    "model2.add(Conv2D(4, kernel_size=(2, 2),\n",
    "                 activation='relu',\n",
    "                 input_shape=smpSize))\n",
    "model2.add(Conv2D(8, kernel_size=(2, 2),\n",
    "                 activation='relu',\n",
    "                 input_shape=smpSize))\n",
    "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model2.add(Conv2D(16, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=smpSize))\n",
    "model2.add(Conv2D(32, kernel_size=(4, 4),\n",
    "                 activation='relu',\n",
    "                 input_shape=smpSize))\n",
    "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model2.add(Flatten())\n",
    "model2.add(Dense(256, activation='sigmoid'))\n",
    "model2.add(Dense(ncat, activation='softmax'))\n",
    "\n",
    "model2.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 27s 455us/step - loss: 0.2858 - acc: 0.9120 - val_loss: 0.0841 - val_acc: 0.9738\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 30s 492us/step - loss: 0.0715 - acc: 0.9787 - val_loss: 0.0539 - val_acc: 0.9836\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 25s 410us/step - loss: 0.0501 - acc: 0.9846 - val_loss: 0.0432 - val_acc: 0.9864\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 27s 451us/step - loss: 0.0383 - acc: 0.9887 - val_loss: 0.0377 - val_acc: 0.9884\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 31s 511us/step - loss: 0.0298 - acc: 0.9914 - val_loss: 0.0369 - val_acc: 0.9879\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 26s 430us/step - loss: 0.0247 - acc: 0.9927 - val_loss: 0.0346 - val_acc: 0.9889\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 31s 517us/step - loss: 0.0195 - acc: 0.9946 - val_loss: 0.0343 - val_acc: 0.9891\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 28s 463us/step - loss: 0.0158 - acc: 0.9955 - val_loss: 0.0319 - val_acc: 0.9892\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 25s 417us/step - loss: 0.0126 - acc: 0.9968 - val_loss: 0.0318 - val_acc: 0.9899\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 27s 443us/step - loss: 0.0103 - acc: 0.9971 - val_loss: 0.0320 - val_acc: 0.9898\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 28s 472us/step - loss: 0.0081 - acc: 0.9981 - val_loss: 0.0315 - val_acc: 0.9902\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 26s 437us/step - loss: 0.0066 - acc: 0.9985 - val_loss: 0.0308 - val_acc: 0.9899\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 31s 524us/step - loss: 0.0053 - acc: 0.9990 - val_loss: 0.0347 - val_acc: 0.9898\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 26s 432us/step - loss: 0.0038 - acc: 0.9994 - val_loss: 0.0294 - val_acc: 0.9909\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 30s 501us/step - loss: 0.0032 - acc: 0.9994 - val_loss: 0.0314 - val_acc: 0.9911\n"
     ]
    }
   ],
   "source": [
    "for i in range(epochs):\n",
    "    model2.fit(imgTrain, onehotTrain, validation_data=(imgTest, onehotTest), batch_size=128, epochs=1, verbose=1)\n",
    "    score = model2.evaluate(imgTest, onehotTest, verbose=0)\n",
    "    deep_score[i] = score[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA\n",
    "For the purpose of this problem, we will not be using a CNN, but rather a more traditional neural network.  The reason for this choice is due to the fact that data representation of PCA works very well as a vector input to the input layer.  To make this example work, we will fit and transform the test set.  Using the test set's fit, the verification set is transformed as well.  This means that the verification set will be represented using the principle parts of the training set.  Although the representation of the verification space is not perfect, it should, in theory, be a viable way to represent the space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = Sequential()\n",
    "\n",
    "model3.add(Dense(400, input_shape=(784,)))\n",
    "model3.add(Dense(300, activation='sigmoid'))\n",
    "model3.add(Dense(200, activation='sigmoid'))\n",
    "model3.add(Dense(100, activation='sigmoid'))\n",
    "model3.add(Dense(ncat, activation='softmax'))\n",
    "\n",
    "model3.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n, h, w, channel = imgTrain.shape\n",
    "X = np.reshape(imgTrain,(n, h*w*channel))\n",
    "pca = PCA() \n",
    "imgTrain_pca = pca.fit_transform(X)\n",
    "n_test = imgTest.shape[0]\n",
    "X_test = np.reshape(imgTest,(n_test, h*w*channel))\n",
    "imgTest_pca = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 6s 106us/step - loss: 0.8975 - acc: 0.7242 - val_loss: 0.3694 - val_acc: 0.8907\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 6s 99us/step - loss: 0.3210 - acc: 0.9059 - val_loss: 0.2839 - val_acc: 0.9176\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 0.2499 - acc: 0.9252 - val_loss: 0.2324 - val_acc: 0.9310\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 6s 100us/step - loss: 0.2016 - acc: 0.9396 - val_loss: 0.1899 - val_acc: 0.9440\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 6s 99us/step - loss: 0.1645 - acc: 0.9510 - val_loss: 0.1643 - val_acc: 0.9502\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 7s 117us/step - loss: 0.1362 - acc: 0.9596 - val_loss: 0.1426 - val_acc: 0.9568\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 0.1136 - acc: 0.9661 - val_loss: 0.1302 - val_acc: 0.9623\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 7s 110us/step - loss: 0.0959 - acc: 0.9720 - val_loss: 0.1151 - val_acc: 0.9634\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 7s 108us/step - loss: 0.0813 - acc: 0.9761 - val_loss: 0.1082 - val_acc: 0.9667\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 7s 109us/step - loss: 0.0687 - acc: 0.9798 - val_loss: 0.1102 - val_acc: 0.9668\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 7s 109us/step - loss: 0.0576 - acc: 0.9830 - val_loss: 0.1028 - val_acc: 0.9666\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 7s 110us/step - loss: 0.0479 - acc: 0.9862 - val_loss: 0.0891 - val_acc: 0.9729\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 0.0393 - acc: 0.9888 - val_loss: 0.0956 - val_acc: 0.9701\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 7s 110us/step - loss: 0.0330 - acc: 0.9910 - val_loss: 0.0892 - val_acc: 0.9728\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 7s 112us/step - loss: 0.0268 - acc: 0.9926 - val_loss: 0.0830 - val_acc: 0.9753\n"
     ]
    }
   ],
   "source": [
    "for i in range(epochs):\n",
    "    model3.fit(imgTrain_pca, onehotTrain, validation_data=(imgTest_pca, onehotTest), batch_size=128, epochs=1, verbose=1)\n",
    "    score = model3.evaluate(imgTest_pca, onehotTest, verbose=0)\n",
    "    pca_score[i] = score[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion\n",
    "By plotting the change in performance of the three models, over the span of 15 epochs, we can see the ability for each method to classify the verification set.  As we can see, the convolution networks have a very high rate of success in the validation within the first few epochs.  PCA, however, does not benefit in this way.  However, the rate at which it learns to classify the verification set increase much faster.  But fails to reach the starting rate of the deep CNN after 15 epochs.  \n",
    "\n",
    "One thing to note is that the time per epoch for PCA on my machine is only 6-7 seconds.  The time required per epoch for the Deep CNN is closer to 30 seconds.  This indicates that we can perform as many has 5 times the amount of epochs in the same amount of time with the PCA method.  Although this will initially provide a classification rate for the verification set, it will start to overtrain quickly. Fortunately, there are various methods, such as dropout layers, that prevent this from occuring.\n",
    "\n",
    "Overall, there are nearly infinite ways to formulate a model for any given classification problem.  In this example, we tested three fairly different methods, all of which provided very good performance on the verification set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12560fd30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(111)\n",
    "ax1.scatter(range(epochs), simple_score, s=10, c='r', label='simple')\n",
    "ax1.scatter(range(epochs), deep_score, s=10, c='g', label='deep')\n",
    "ax1.scatter(range(epochs), pca_score, s=10, c='b', label='pca')\n",
    "ax1.plot(range(epochs), simple_score, c='r', label='simple')\n",
    "ax1.plot(range(epochs), deep_score, c='g', label='deep')\n",
    "ax1.plot(range(epochs), pca_score, c='b', label='pca')\n",
    "plt.legend(loc='lower right');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
